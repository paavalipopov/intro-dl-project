{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import wandb\n",
    "\n",
    "dataset_match = {\n",
    "    \"cobre\": \"COBRE\",\n",
    "    \"abide\": \"ABIDE\",\n",
    "    \"synth1\": \"Synthetic1\",\n",
    "    \"synth2\": \"Synthetic2\",\n",
    "}\n",
    "\n",
    "model_match = {\n",
    "    \"lstm\": \"LSTM\",\n",
    "    \"mean_lstm\": \"Mean LSTM\",\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"mean_transformer\": \"Mean Transformer\",\n",
    "    \"dice\": \"DICE\",\n",
    "    \"glob_dice\": \"Pretuned DICE\",\n",
    "}\n",
    "\n",
    "def load_normal(proj_name):\n",
    "    api = wandb.Api(timeout=19)\n",
    "    # Project is specified by <entity/project-name>\n",
    "    runs = api.runs(f\"{proj_name}\")\n",
    "\n",
    "    summary_list = []\n",
    "    for run in runs: \n",
    "        # .summary contains the output keys/values for metrics like accuracy.\n",
    "        #  We call ._json_dict to omit large files \n",
    "        summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    AUC_score = []\n",
    "    accuracy = []\n",
    "    for run in summary_list:\n",
    "        AUC_score.append(run[\"test_score\"])\n",
    "        accuracy.append(run[\"test_accuracy\"])\n",
    "    \n",
    "    return AUC_score, accuracy\n",
    "\n",
    "def load_metrics(paths_dict, ds_dict, model_dict):\n",
    "    data_list = []\n",
    "    mean_list = []\n",
    "\n",
    "    for model_name in paths_dict.keys():\n",
    "        print(model_name)\n",
    "        for dataset_name in paths_dict[model_name].keys():\n",
    "            print(\"\\t \", dataset_name)\n",
    "\n",
    "            path = paths_dict[model_name][dataset_name]\n",
    "\n",
    "            auc, acc = load_normal(path)\n",
    "            \n",
    "            data_list.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"AUC\": auc,\n",
    "                        \"Accuracy\": acc,\n",
    "                        \"Model\": [model_dict[model_name]]*len(auc),\n",
    "                        \"Dataset\": [ds_dict[dataset_name]]*len(auc),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            mean_list.append(\n",
    "                pd.DataFrame(\n",
    "                    {\n",
    "                        \"Mean\": np.mean(auc),\n",
    "                        \"Var\": np.var(auc),\n",
    "                        \"Model\": model_dict[model_name],\n",
    "                        \"Dataset\": ds_dict[dataset_name],\n",
    "                    },\n",
    "                    index=[0]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return pd.concat(data_list), pd.concat(mean_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Plot boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm\n",
      "\t  abide\n",
      "\t  cobre\n",
      "\t  synth1\n",
      "\t  synth2\n",
      "mean_lstm\n",
      "\t  abide\n",
      "\t  cobre\n",
      "\t  synth1\n",
      "\t  synth2\n",
      "transformer\n",
      "\t  abide\n",
      "\t  cobre\n",
      "\t  synth1\n",
      "\t  synth2\n",
      "mean_transformer\n",
      "\t  abide\n",
      "\t  cobre\n",
      "\t  synth1\n",
      "\t  synth2\n",
      "dice\n",
      "\t  abide\n",
      "\t  cobre\n",
      "\t  synth1\n",
      "\t  synth2\n"
     ]
    }
   ],
   "source": [
    "projects = {\n",
    "    \"lstm\": {\n",
    "        \"abide\": \"introdl-exp-lstm-abide\",\n",
    "        \"cobre\": \"introdl-exp-lstm-cobre\",\n",
    "        \"synth1\": \"introdl-exp-lstm-synth1\",\n",
    "        \"synth2\": \"introdl-exp-lstm-synth2\",\n",
    "    },\n",
    "    \"mean_lstm\": {\n",
    "        \"abide\": \"introdl-exp-mean_lstm-abide\",\n",
    "        \"cobre\": \"introdl-exp-mean_lstm-cobre\",\n",
    "        \"synth1\": \"introdl-exp-mean_lstm-synth1\",\n",
    "        \"synth2\": \"introdl-exp-mean_lstm-synth2\",\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"abide\": \"introdl-exp-transformer-abide\",\n",
    "        \"cobre\": \"introdl-exp-transformer-cobre\",\n",
    "        \"synth1\": \"introdl-exp-transformer-synth1\",\n",
    "        \"synth2\": \"introdl-exp-transformer-synth2\",\n",
    "    },\n",
    "    \"mean_transformer\": {\n",
    "        \"abide\": \"introdl-exp-mean_transformer-abide\",\n",
    "        \"cobre\": \"introdl-exp-mean_transformer-cobre\",\n",
    "        \"synth1\": \"introdl-exp-mean_transformer-synth1\",\n",
    "        \"synth2\": \"introdl-exp-mean_transformer-synth2\",\n",
    "    },\n",
    "    \"dice\": {\n",
    "        \"abide\": \"introdl-exp-dice-abide\",\n",
    "        \"cobre\": \"introdl-exp-dice-cobre\",\n",
    "        \"synth1\": \"introdl-exp-dice-synth1\",\n",
    "        \"synth2\": \"introdl-exp-dice-synth2\",\n",
    "    },\n",
    "    # \"glob_dice\": {\n",
    "    #     \"abide\": \"introdl-exp-dice-global_abide\",\n",
    "    #     \"cobre\": \"introdl-exp-dice-global_cobre\",\n",
    "    #     \"synth1\": \"introdl-exp-dice-global_synth1\",\n",
    "    #     \"synth2\": \"introdl-exp-dice-global_synth2\",\n",
    "    # },\n",
    "}\n",
    "\n",
    "data, stat_data = load_metrics(projects, dataset_match, model_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "sns.set_theme(\n",
    "    style=\"whitegrid\", \n",
    "    font_scale = 1.5, \n",
    "    rc={'figure.figsize':(10,3)}\n",
    ")\n",
    "\n",
    "\n",
    "palette = {\n",
    "    \"LSTM\": \"C0\",\n",
    "    \"Mean LSTM\": \"C1\",\n",
    "    \"Transformer\": \"C2\",\n",
    "    \"Mean Transformer\": \"C3\",\n",
    "    \"DICE\": \"C4\",\n",
    "    \"Pretuned DICE\": \"C5\",\n",
    "}\n",
    "\n",
    "\n",
    "ax = sns.boxplot(\n",
    "    x=\"Dataset\", \n",
    "    y=\"AUC\",\n",
    "    hue=\"Model\",\n",
    "    data=data,\n",
    "    palette=palette,\n",
    "    showfliers = False\n",
    ")\n",
    "\n",
    "ax.set(ylabel=\"AUROC\")\n",
    "\n",
    "ax.axhline(0.5)\n",
    "plt.yticks([0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "# plt.xticks(rotation=20)\n",
    "# sns.despine(offset=10, trim=True)\n",
    "plt.legend(bbox_to_anchor=(1.01, 1.0), loc='upper left', borderaxespad=0)\n",
    "\n",
    "\n",
    "sns.set_theme(\n",
    "    font_scale = 1,\n",
    ")\n",
    "\n",
    "plt.ylim(0.4, 1.05)\n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"aucs.eps\",\n",
    "    format=\"eps\",\n",
    "    # dpi=300,\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create panel of saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "sns.reset_defaults()\n",
    "\n",
    "models = [\n",
    "    \"lstm\",\n",
    "    \"mean_lstm\",\n",
    "    \"transformer\",\n",
    "    \"mean_transformer\",\n",
    "    \"dice\",\n",
    "    # \"pretuned_dice\",\n",
    "]\n",
    "datasets = [\n",
    "    \"abide\",\n",
    "    \"cobre\",\n",
    "    \"synth1\",\n",
    "    \"synth2\",\n",
    "]\n",
    "\n",
    "# fig, axs = plt.subplots(2*len(models), len(datasets), figsize=(10, 10), constrained_layout = True)\n",
    "fig, axs = plt.subplots(2*len(models), len(datasets), figsize=(3.6*len(datasets), 3*len(models)))\n",
    "# fig, axs = plt.subplots(2*len(models), len(datasets))\n",
    "# fig.tight_layout()\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        for target in range(2):\n",
    "            if model == \"pretuned_dice\":\n",
    "                image = Image.open(f'../assets/introspection/introdl-introspection-dice-global_{dataset}/k_00/saliency/colormap/general_{target}.png')\n",
    "            else:\n",
    "                image = Image.open(f'../assets/introspection/introdl-introspection-{model}-{dataset}/k_00/saliency/colormap/general_{target}.png')\n",
    "            # image0.show()\n",
    "            axs[2*i + target, j].imshow(image)\n",
    "            axs[2*i + target, j].set_xticks([])\n",
    "            axs[2*i + target, j].set_yticks([])\n",
    "            \n",
    "            if j == 0:\n",
    "                if target == 0:\n",
    "                    axs[2*i + target, j].set_ylabel(f\"Class {target},\\n {model}\", fontsize = 16)\n",
    "                else:\n",
    "                    axs[2*i + target, j].set_ylabel(f\"Class {target}\", fontsize = 16)\n",
    "            if i == 0 and target == 0:\n",
    "                axs[2*i + target, j].set_xlabel(dataset_match[dataset], fontsize = 16)\n",
    "                axs[2*i + target, j].xaxis.set_label_position('top') \n",
    "            \n",
    "\n",
    "fig.tight_layout(pad = 0.05)\n",
    "# plt.subplots_adjust(left=0.1,\n",
    "#                     bottom=0.1,\n",
    "#                     right=0.9,\n",
    "#                     top=0.9,\n",
    "#                     wspace=0.4,\n",
    "#                     hspace=0.4)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig(\n",
    "    \"saliency.png\",\n",
    "    format=\"png\",\n",
    "    dpi=150,\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = [\n",
    "    \"lstm\",\n",
    "    \"mean_lstm\",\n",
    "    \"transformer\",\n",
    "    \"mean_transformer\",\n",
    "    \"dice\",\n",
    "    # \"pretuned_dice\",\n",
    "]\n",
    "datasets = [\n",
    "    \"abide\",\n",
    "    \"cobre\",\n",
    "    \"synth1\",\n",
    "    \"synth2\",\n",
    "]\n",
    "\n",
    "model_match = {\n",
    "    \"lstm\": \"LSTM\",\n",
    "    \"mean_lstm\": \"Mean\\nLSTM\",\n",
    "    \"transformer\": \"Transformer\",\n",
    "    \"mean_transformer\": \"Mean\\nTransformer\",\n",
    "    \"dice\": \"DICE\",\n",
    "    \"glob_dice\": \"Pretuned\\nDICE\",\n",
    "}\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(3.7*len(datasets), 3*len(models)))\n",
    "subfigs = fig.subfigures(len(models), len(datasets)+1, width_ratios=[0.1]+ [1]*(len(datasets)))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        if j == 0:\n",
    "            subfigs[i, j].suptitle(f\"{model_match[model]}\", fontsize = 16, x = -0.2, y = 0.5, rotation = \"vertical\", ha=\"center\", va=\"center\")\n",
    "            axs = subfigs[i, j].subplots(2, 1)\n",
    "            for target in range(2):\n",
    "                axs[target].text(1.5, 0.5, f'Class {target}', ha='center', va='center', fontsize = 16, rotation = \"vertical\")\n",
    "                axs[target].axis('off')\n",
    "\n",
    "        axs = subfigs[i, j+1].subplots(2, 1)\n",
    "        if i == 0:\n",
    "            subfigs[i, j+1].suptitle(f\"{dataset_match[dataset]}\", fontsize = 16, x = 0.5, y = 1.02, ha=\"center\", va=\"center\")\n",
    "        for target in range(2):\n",
    "            image = Image.open(f'../assets/introspection/introdl-introspection-{model}-{dataset}/k_00/saliency/colormap/general_{target}.png')\n",
    "            # image0.show()\n",
    "            axs[target].imshow(image)\n",
    "            axs[target].set_xticks([])\n",
    "            axs[target].set_yticks([])\n",
    "            \n",
    "\n",
    "# plt.show()\n",
    "plt.savefig(\n",
    "    \"saliency.eps\",\n",
    "    format=\"eps\",\n",
    "    # dpi=150,\n",
    "    bbox_inches='tight',\n",
    ")\n",
    "\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "introdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bebb5da7f3efd7be6aaa129981c7a14bb5268c74b218ff0a2e7eee4fb8e1efb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
